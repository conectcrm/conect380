# ‚úÖ Checklist de Valida√ß√£o - Sistema de Alerting

**Antes de ir para produ√ß√£o, validar TODOS os itens abaixo.**

---

## üìã 1. Configura√ß√£o B√°sica

### Vari√°veis de Ambiente
- [ ] Arquivo `.env.alerting` criado a partir do `.env.alerting.example`
- [ ] `SLACK_WEBHOOK_URL` configurado e testado
- [ ] `SMTP_USERNAME` e `SMTP_PASSWORD` configurados (se usar email)
- [ ] `PAGERDUTY_SERVICE_KEY` configurado (se usar PagerDuty)
- [ ] `GRAFANA_ADMIN_PASSWORD` alterado do padr√£o

### Arquivos de Configura√ß√£o
- [ ] `backend/config/alertmanager.yml` existe e est√° v√°lido
- [ ] `backend/config/alert-rules.yml` existe e est√° v√°lido
- [ ] `backend/config/slo-definitions.yml` existe e est√° v√°lido
- [ ] `observability/prometheus.yml` atualizado com alerting
- [ ] `docker-compose.yml` atualizado com Prometheus, Alertmanager e Grafana

---

## üöÄ 2. Infraestrutura Docker

### Servi√ßos Rodando
- [ ] Prometheus iniciado: `docker-compose ps prometheus`
- [ ] Alertmanager iniciado: `docker-compose ps alertmanager`
- [ ] Grafana iniciado: `docker-compose ps grafana`
- [ ] Healthchecks passando: `docker-compose ps` (todos "healthy")

### Conectividade
- [ ] Prometheus acess√≠vel: http://localhost:9090
- [ ] Alertmanager acess√≠vel: http://localhost:9093
- [ ] Grafana acess√≠vel: http://localhost:3002
- [ ] Backend expondo m√©tricas: http://localhost:3001/metrics

### Volumes Persistentes
- [ ] Volume `prometheus_data` criado
- [ ] Volume `alertmanager_data` criado
- [ ] Volume `grafana_data` criado
- [ ] Dados persistem ap√≥s restart: `docker-compose restart prometheus`

---

## üîî 3. Alertas Configurados

### Prometheus Alert Rules
- [ ] Prometheus carregou alert-rules.yml: http://localhost:9090/rules
- [ ] 14 alertas aparecem na p√°gina Rules
- [ ] N√£o h√° erros de sintaxe PromQL
- [ ] Valida√ß√£o manual: `docker-compose exec prometheus promtool check rules /etc/prometheus/alert-rules.yml`

### Alertmanager Routing
- [ ] Alertmanager carregou alertmanager.yml: http://localhost:9093/#/status
- [ ] 5 receivers configurados (default, critical, warning, info, slo)
- [ ] Rotas por severidade corretas
- [ ] Inibi√ß√£o rules corretas
- [ ] Valida√ß√£o manual: `docker-compose exec alertmanager amtool check-config /etc/alertmanager/alertmanager.yml`

### Integra√ß√£o Prometheus ‚Üí Alertmanager
- [ ] Prometheus aponta para Alertmanager: http://localhost:9090/config (se√ß√£o `alerting`)
- [ ] Target do Alertmanager est√° UP: http://localhost:9090/targets
- [ ] Alertas chegam no Alertmanager: http://localhost:9093/#/alerts

---

## üß™ 4. Testes de Alertas

### Script de Teste
- [ ] Script executa sem erros: `.\scripts\test-alerting.ps1 -Severity all`
- [ ] Todos os alertas foram enviados (8/8 success)
- [ ] Alertas aparecem no Alertmanager: http://localhost:9093/#/alerts

### Teste por Severidade
- [ ] Critical alerts enviados: `.\scripts\test-alerting.ps1 -Severity critical`
- [ ] Warning alerts enviados: `.\scripts\test-alerting.ps1 -Severity warning`
- [ ] Info alerts enviados: `.\scripts\test-alerting.ps1 -Severity info`
- [ ] SLO alerts enviados: `.\scripts\test-alerting.ps1 -Severity slo`

### Notifica√ß√µes Recebidas
- [ ] **Slack - Critical**: Alerta chegou em `#alerts-critical`
- [ ] **Slack - Warning**: Alerta chegou em `#alerts-warning`
- [ ] **Slack - Info**: Alerta chegou em `#alerts-info`
- [ ] **Slack - SLO**: Alerta chegou em `#slo-violations`
- [ ] **Email**: Email recebido no inbox configurado
- [ ] **PagerDuty**: Incident criado no PagerDuty (se configurado)

### Roteamento Correto
- [ ] Critical ‚Üí Email + Slack + PagerDuty (3 canais)
- [ ] Warning ‚Üí Email + Slack (2 canais)
- [ ] Info ‚Üí Slack apenas (1 canal)
- [ ] SLO ‚Üí Slack `#slo-violations` (1 canal)

---

## üìä 5. Grafana

### Datasource
- [ ] Prometheus datasource provisionado automaticamente
- [ ] Datasource est√° "working": http://localhost:3002/datasources
- [ ] Teste de query funciona: `up{job="conectcrm-backend"}`

### Dashboards
- [ ] Dashboard folder "ConectCRM" existe
- [ ] Dashboards importados corretamente
- [ ] Queries retornam dados (n√£o vazio)
- [ ] Pain√©is renderizam sem erros

### Alertas no Grafana (Opcional)
- [ ] Alertas do Prometheus aparecem no Grafana
- [ ] Painel "Alerts" mostra alertas ativos
- [ ] Hist√≥rico de alertas funciona

---

## üìö 6. Documenta√ß√£o

### Runbooks Dispon√≠veis
- [ ] `backend/docs/runbooks/api-down.md` existe
- [ ] `backend/docs/runbooks/db-pool-exhausted.md` existe
- [ ] Runbooks est√£o atualizados com comandos corretos
- [ ] Links de runbook nos alertas est√£o corretos

### README e Guias
- [ ] `ALERTING_README.md` existe e est√° completo
- [ ] `QUICKSTART_ALERTING.md` existe e est√° correto
- [ ] `SEMANA_5_ALERTING_SLOS.md` existe
- [ ] `PROMQL_QUERIES.md` existe com queries √∫teis
- [ ] `CONCLUSAO_SEMANA_5.md` existe

### Links Funcionando
- [ ] Todos os links internos funcionam (Markdown)
- [ ] Links para Grafana est√£o corretos
- [ ] Links para runbooks est√£o corretos
- [ ] Links externos (Google SRE Book, etc.) funcionam

---

## üîê 7. Seguran√ßa

### Credenciais
- [ ] Grafana admin password alterado do padr√£o
- [ ] SMTP password √© App Password (n√£o senha real)
- [ ] Vari√°veis de ambiente N√ÉO commitadas no git
- [ ] `.env.alerting` est√° no `.gitignore`

### Acessos
- [ ] Apenas admins t√™m acesso ao Alertmanager
- [ ] Apenas admins t√™m acesso ao Prometheus
- [ ] Grafana tem autentica√ß√£o ativada
- [ ] PagerDuty integration key √© secreta

### HTTPS (Produ√ß√£o)
- [ ] Nginx reverse proxy configurado (se produ√ß√£o)
- [ ] SSL/TLS certificado v√°lido
- [ ] Alertmanager atr√°s de autentica√ß√£o
- [ ] Prometheus atr√°s de autentica√ß√£o

---

## üéØ 8. SLOs

### SLOs Definidos
- [ ] 7 SLOs t√™m targets claros (99.9%, P95 < 2s, etc.)
- [ ] Error budgets calculados corretamente
- [ ] Janelas de tempo adequadas (1d, 7d, 30d)
- [ ] SLIs s√£o mensur√°veis via PromQL

### M√©tricas Dispon√≠veis
- [ ] Backend exp√µe todas as m√©tricas necess√°rias
- [ ] Queries PromQL para SLIs funcionam
- [ ] Histogramas configurados corretamente (buckets)
- [ ] M√©tricas de neg√≥cio (tickets) funcionam

### Error Budget Policy
- [ ] 4 n√≠veis de budget definidos (>80%, 50-80%, 20-50%, <20%)
- [ ] A√ß√µes claras para cada n√≠vel
- [ ] Equipe entende a pol√≠tica
- [ ] Processo de deploy freeze documentado

---

## üö® 9. Procedimentos de Incidente

### Escala√ß√£o
- [ ] Matriz de escala√ß√£o definida (on-call ‚Üí tech lead ‚Üí CTO)
- [ ] Tempos de escala√ß√£o claros (5min, 10min, 15min)
- [ ] Contatos de emerg√™ncia atualizados
- [ ] PagerDuty on-call schedule configurado (se usar)

### Runbooks
- [ ] Equipe sabe onde encontrar runbooks
- [ ] Runbooks testados em simula√ß√£o
- [ ] Comandos nos runbooks funcionam
- [ ] RTO/RPO documentados

### Postmortem (Planejado)
- [ ] Template de postmortem criado (Semana 6)
- [ ] Processo de postmortem definido
- [ ] Respons√°vel por postmortems definido
- [ ] Canal para compartilhar postmortems

---

## üßë‚Äçüíª 10. Treinamento da Equipe

### On-call Engineers
- [ ] Treinados em como acessar Alertmanager
- [ ] Conhecem os runbooks principais
- [ ] Sabem como silenciar alertas
- [ ] Sabem como escalar incidentes

### Tech Leads
- [ ] Entendem SLOs e error budgets
- [ ] Sabem analisar queries PromQL
- [ ] Conhecem processo de postmortem
- [ ] Sabem configurar novos alertas

### Time de Desenvolvimento
- [ ] Entendem impacto de deploys no error budget
- [ ] Sabem criar m√©tricas custom
- [ ] Conhecem processo de deploy freeze
- [ ] Sabem onde ver status de SLOs

---

## üìà 11. Monitoramento Cont√≠nuo

### M√©tricas do Sistema de Alerting
- [ ] Prometheus scrape rate: > 95% success
- [ ] Alertmanager uptime: > 99.9%
- [ ] Grafana response time: < 1s
- [ ] Notifica√ß√µes delivery rate: > 99%

### Health Checks
- [ ] Health check Prometheus: http://localhost:9090/-/healthy
- [ ] Health check Alertmanager: http://localhost:9093/-/healthy
- [ ] Health check Grafana: http://localhost:3002/api/health

### Logs
- [ ] Logs do Prometheus n√£o t√™m erros cr√≠ticos
- [ ] Logs do Alertmanager n√£o t√™m falhas de envio
- [ ] Logs do Grafana n√£o t√™m erros de datasource

---

## üéõÔ∏è 12. Tuning e Otimiza√ß√£o

### Alert Rules
- [ ] Thresholds adequados (n√£o muito sens√≠veis)
- [ ] Dura√ß√µes ajustadas (evitar flapping)
- [ ] Annotations completas (summary, description, runbook)
- [ ] Labels corretos (severity, component)

### Alertmanager
- [ ] Group wait adequado (0s para critical, 30s warning)
- [ ] Repeat interval razo√°vel (5min critical, 3h warning)
- [ ] Resolve timeout correto (5min)
- [ ] Inibi√ß√£o evita spam

### Prometheus
- [ ] Scrape interval adequado (15s)
- [ ] Evaluation interval correto (30s)
- [ ] Retention time suficiente (15 dias)
- [ ] Storage n√£o est√° cheio

---

## üîÑ 13. Backup e Disaster Recovery

### Backup de Configura√ß√µes
- [ ] Configura√ß√µes versionadas no git
- [ ] `.env.alerting` tem backup seguro (fora do git)
- [ ] Dashboards Grafana exportados (JSON)

### Backup de Dados
- [ ] Volumes Docker com backup peri√≥dico
- [ ] Prometheus TSDB com snapshot
- [ ] Grafana database com backup
- [ ] Alertmanager state com backup

### Disaster Recovery
- [ ] Procedimento de restore documentado
- [ ] Tempo de restore testado (< 30min)
- [ ] Backup offsite configurado
- [ ] RTO/RPO definidos

---

## ‚úÖ 14. Valida√ß√£o Final

### Teste End-to-End
- [ ] Deploy uma mudan√ßa no backend
- [ ] Observar m√©tricas no Prometheus
- [ ] Simular um erro (ex: derrubar backend)
- [ ] Verificar alerta disparou
- [ ] Verificar notifica√ß√£o chegou
- [ ] Seguir runbook para resolver
- [ ] Verificar alerta resolveu
- [ ] Verificar resolved notification

### Teste de Carga
- [ ] Sistema aguenta tr√°fego esperado
- [ ] M√©tricas n√£o atrasam
- [ ] Alertas disparam corretamente sob carga
- [ ] Grafana continua responsivo

### Teste de Failover
- [ ] Prometheus reinicia sem perder dados
- [ ] Alertmanager mant√©m state ap√≥s restart
- [ ] Grafana reconecta automaticamente
- [ ] Alertas continuam funcionando

---

## üéØ Crit√©rios de Aceita√ß√£o

**Sistema est√° pronto para produ√ß√£o quando:**

‚úÖ **Todas as 200+ checklist items acima est√£o marcadas**

‚úÖ **Teste end-to-end completo passou**

‚úÖ **Equipe treinada e confort√°vel com ferramentas**

‚úÖ **Documenta√ß√£o completa e atualizada**

‚úÖ **Backups configurados e testados**

---

## üìä M√©tricas de Sucesso (Medir ap√≥s 1 m√™s)

### Objetivos T√©cnicos
- MTTD (Mean Time To Detect): **< 1 minuto** ‚úÖ Target: 30s
- MTTR (Mean Time To Resolve): **< 15 minutos** ‚è≥ A medir
- Alert Accuracy: **> 95%** ‚è≥ A medir
- False Positive Rate: **< 5%** ‚è≥ A medir

### Objetivos de Neg√≥cio
- Disponibilidade: **> 99.9%** (SLO)
- Lat√™ncia P95: **< 2s** (SLO)
- Satisfa√ß√£o da equipe on-call: **> 4/5**
- Tempo de onboarding: **< 1 hora** (com este checklist)

---

**Status**: ‚è≥ Em valida√ß√£o  
**Respons√°vel**: _[Nome]_  
**Data de valida√ß√£o**: _[Data]_  
**Aprovado por**: _[Nome]_

---

**√öltima atualiza√ß√£o**: 17 de novembro de 2025
